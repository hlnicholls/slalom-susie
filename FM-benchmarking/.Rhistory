for(i in 2){
print('set gamma before index.fun S==0')
print(class(set.gamma[[i]]))
print(dim(set.gamma[[i]]))
print(set.gamma[[i]])
write.csv(set.gamma[[i]], "~/Desktop/carma_gamma_matrix.csv", row.names = FALSE)
matrix.gamma[[i]]<-index.fun(set.gamma[[i]])
print('i')
print(i)
print('matrix gamma (after index.fun) when S == 0')
print(class(matrix.gamma[[i]]))
print(dim(matrix.gamma[[i]]))
print(matrix.gamma[[i]])
if(length(C.list[[2]])<ncol(set.gamma[[i]])){
C.list[[2]][[ncol(set.gamma[[i]])]]<-as(Matrix(nrow=0,ncol=p,sparse = T,data=0),'CsparseMatrix')
C.list[[1]][[ncol(set.gamma[[i]])]]<-integer(0)
computed.index<-integer(0)
}else{
computed.index<-match.dgCMatrix(C.list[[2]][[ncol(set.gamma[[i]])]],matrix.gamma[[i]])
}
print('C.list setup before use (S==0)')
print(C.list)
p_S=dim(set.gamma[[i]])[2]
if(length(na.omit(computed.index))==0){
cat("Inputs for C++ marginal likelihood function:\n")
cat("set_gamma[[i]]", length(set.gamma[[i]]), "\n")
cat("Sigma", length(Sigma), "\n")
cat("z length", length(z), "\n")
cat(paste0("tau=", tau.sample, ", p_S=", p_S, ", y_sigma=", y.var), "\n")
print('z:')
print(z)
set.gamma.margin[[i]]<-apply(set.gamma[[i]],1,marginal_likelihood,Sigma=Sigma,z=z,tau=tau.sample,p_S=p_S,y_sigma=y.var)
print('i')
print(i)
print('set.gamma.margin[[i]] when S == 0')
print(set.gamma.margin[[i]])
C.list[[1]][[ncol(set.gamma[[i]])]]<-c(C.list[[1]][[ncol(set.gamma[[i]])]],set.gamma.margin[[i]])
C.list[[2]][[ncol(set.gamma[[i]])]]<-rbind(C.list[[2]][[ncol(set.gamma[[i]])]],matrix.gamma[[i]])
set.gamma.prior[[i]]<-apply(matrix.gamma[[i]],1,prior.dist)
print('set.gamma.prior[[i]] when S=0')
print(set.gamma.prior[[i]])
set.gamma.margin[[i]]=set.gamma.prior[[i]]+set.gamma.margin[[i]]
}else{
set.gamma.margin[[i]]<-rep(NA,nrow(matrix.gamma[[i]]))
set.gamma.margin[[i]][!is.na(computed.index)]<-C.list[[1]][[ncol(set.gamma[[i]])]][na.omit(computed.index)]
if(sum(is.na(computed.index))!=0){
set.gamma.margin[[i]][is.na(computed.index)]<-apply(set.gamma[[i]][is.na(computed.index),,drop=F],1,marginal_likelihood,Sigma=Sigma,z=z,tau=tau.sample,p_S=p_S,y_sigma=y.var)
}
C.list[[1]][[ncol(set.gamma[[i]])]]<-c(C.list[[1]][[ncol(set.gamma[[i]])]],set.gamma.margin[[i]][is.na(computed.index)])
C.list[[2]][[ncol(set.gamma[[i]])]]<-rbind(C.list[[2]][[ncol(set.gamma[[i]])]],matrix.gamma[[i]][is.na(computed.index),,drop=F])
set.gamma.margin[[i]]<- set.gamma.margin[[i]]+ apply(matrix.gamma[[i]],1,prior.dist)
}
print('C.list when S==0')
print(dim(C.list))
print(class(C.list))
print(C.list)
}
add.B<-list()
add.B[[1]]<-c(set.gamma.margin[[2]])
add.B[[2]]<-matrix.gamma[[2]]
print('add.B when S==0')
print(dim(add.B))
print(class(add.B))
print(add.B)
}
########## add visited models into the storage space of models###############
add.index<-match.dgCMatrix(B.list[[2]],add.B[[2]])
print('add.index setup')
print(add.index)
if(length(which(!is.na(add.index)))>10){
check.index<-sample(which(!is.na(add.index)),10)
}
if(length(na.omit(add.index))!=0){
B.list[[1]]<-c((B.list[[1]]),(add.B[[1]][is.na(add.index)]))
B.list[[2]]<-rbind(B.list[[2]],add.B[[2]][is.na(add.index),,drop=F])
}else{
B.list[[1]]<-c((B.list[[1]]),(add.B[[1]]))
B.list[[2]]<-rbind(B.list[[2]],add.B[[2]])
}
B.list[[2]]<-B.list[[2]][order(B.list[[1]],decreasing = T),]
B.list[[1]]<-B.list[[1]][order(B.list[[1]],decreasing = T)]
cat("S==", working.S, "B_list:", "lengths:", length(B.list[[1]]), "\n")
print(dim(B.list[[2]]))
print(B.list)
###################Select next visiting model##############
if(length(working.S)!=0){
set.star<-data.frame(set.index=1:3,gamma.set.index=rep(NA,3),margin=rep(NA,3))
for(i in 1){
aa<-set.gamma.margin[[i]]-current.log.margin
aa<-aa-aa[which.max(aa)]
if(length(which(is.nan(aa)))!=0){
aa[which(is.nan(aa))]<-min(aa)
}
set.star$gamma.set.index[i] <-c(sample(1:length(set.gamma.margin[[i]]),1,prob=exp(aa)))
set.star$margin[i]<-set.gamma.margin[[i]][  set.star$gamma.set.index[i]]
rm(aa)
}
#######The Bayesian hypothesis testing for Z-scores/LD discrepancies########
if(outlier.switch){
for(i in 2:length(set.gamma)){
repeat{
aa<-set.gamma.margin[[i]]-current.log.margin
aa<-aa-aa[which.max(aa)]
if(length(which(is.nan(aa)))!=0){
aa[which(is.nan(aa))]<-min(aa[!is.na(aa)])
}
set.star$gamma.set.index[i]<-c(sample((1:length(set.gamma.margin[[i]])),
1,prob=exp(aa)))
set.star$margin[i]<-set.gamma.margin[[i]][  set.star$gamma.set.index[i]]
test.S<-set.gamma[[i]][set.star$gamma.set.index[i],]
modi.Sigma<-Sigma
temp.Sigma<-Sigma
if(length(test.S)>1){
modi.ld.S<- modi.Sigma[test.S,test.S]
opizer<-optimize(ridge.fun,interval=c(0,1),maximum = T)
modi.ld.S<-opizer$maximum*modi.ld.S+(1-opizer$maximum)*diag(nrow(modi.ld.S))
modi.Sigma[test.S,test.S]<-modi.ld.S
test.log.BF<-outlier_likelihood(test.S,Sigma,z,outlier.tau,length(test.S),1)-outlier_likelihood(test.S,modi.Sigma,z,outlier.tau,length(test.S),1)
test.log.BF<--abs(test.log.BF)
print(paste0('Outlier BF: ', test.log.BF))
print(test.S)
print(paste0('This is xi hat: ', opizer))
}
if(exp(test.log.BF)<outlier.BF.index){
set.gamma[[i]]<-set.gamma[[i]][-set.star$gamma.set.index[i],]
set.gamma.margin[[i]]<-set.gamma.margin[[i]][-set.star$gamma.set.index[i]]
conditional.S<-c(conditional.S,test.S[is.na(match(test.S,working.S))])
conditional.S<-unique(conditional.S)
}else{
break
}
}
rm(aa)
}
}else{
for(i in 2:length(set.gamma)){
aa<-set.gamma.margin[[i]]-current.log.margin
aa<-aa-aa[which.max(aa)]
if(length(which(is.nan(aa)))!=0){
aa[which(is.nan(aa))]<-min(aa[!is.na(aa)])
}
set.star$gamma.set.index[i]<-c(sample((1:length(set.gamma.margin[[i]])),
1,prob=exp(aa)))
set.star$margin[i]<-set.gamma.margin[[i]][  set.star$gamma.set.index[i]]
rm(aa)
}
}
print(set.star)
if(length(working.S)==num.causal){
set.star<-set.star[-2,]
aa<-set.star$margin-current.log.margin-max(set.star$margin-current.log.margin)
sec.sample<-sample(c(1,3),1,prob=exp(aa))
S<-set.gamma[[sec.sample]][set.star$gamma.set.index[[which(sec.sample==set.star$set.index)]] ,]
}else{
aa<-set.star$margin-current.log.margin-max(set.star$margin-current.log.margin)
sec.sample<-sample(1:3,1,prob=exp(aa) )
S<-set.gamma[[sec.sample]][set.star$gamma.set.index[[sec.sample]] ,]
}
}else{
set.star<-data.frame(set.index=rep(1,3),gamma.set.index=rep(NA,3),margin=rep(NA,3))
aa<-set.gamma.margin[[2]]-current.log.margin
aa<-aa-aa[which.max(aa)]
if(length(which(is.nan(aa)))!=0){
aa[which(is.nan(aa))]<-min(aa)
}
set.star$gamma.set.index[2] <-c(sample((1:length(set.gamma.margin[[2]]))[order(exp(aa),decreasing = T)[1:(min(length(aa),floor(p/2)))]],
1,prob=exp(aa)[order(exp(aa),decreasing = T)[1:(min(length(aa),floor(p/2)))]]))
set.star$margin[2]<-set.gamma.margin[[2]][  set.star$gamma.set.index[2]]
S<-set.gamma[[2]][set.star$gamma.set.index[2],]
print('new S:')
print(S)
print('set star when S==0')
print(set.star)
}
print(paste0('this is running S: ',paste0(S,collapse = ',')))
S<-unique(c(S,conditional.S))
}
}
######Output of the results of the module function######
result.B.list<-list()
if(!is.null(conditional.S)){
all.c.index<-c()
for(tt in conditional.S){
c.index<-(B.list[[2]]@i[min(length(B.list[[2]]@i),(B.list[[2]]@p[tt]+1)):B.list[[2]]@p[tt+1]])+1
all.c.index<-c(all.c.index,c.index)
}
all.c.index<-unique(all.c.index)
temp.B.list<-list()
temp.B.list[[1]]<-B.list[[1]][-all.c.index]
temp.B.list[[2]]<-B.list[[2]][-all.c.index,]
}else{
temp.B.list<-list()
temp.B.list[[1]]<-B.list[[1]]
temp.B.list[[2]]<-B.list[[2]]
}
result.B.list<-list()
result.B.list[[1]]<-temp.B.list[[1]][(1:min(B,nrow(temp.B.list[[2]])))]
result.B.list[[2]]<-temp.B.list[[2]][(1:min(B,nrow(temp.B.list[[2]]))),]
if(num.causal==1){
single.set<-matrix(1:p,p,1)
single.marginal<-apply(single.set,1,marginal_likelihood,Sigma=Sigma,z=z,tau=tau.sample,p_S=p_S,y_sigma=y.var)
aa<-single.marginal-max(single.marginal,na.rm=T)
prob.sum<-sum(exp(aa))
result.prob<-(exp(aa))/prob.sum
}else{
result.prob<-PIP.func(result.B.list[[1]],result.B.list[[2]])
}
print('conditional.S')
print(conditional.S)
conditional.S.list<-data.frame(Index=conditional.S,Z=z[conditional.S,])
if(!is.null(output.labels)){
if(dir.exists(output.labels)==F ){
dir.create(output.labels,recursive = T)
}
write.table(result.B.list[[1]],file=paste0(output.labels,'/post_',label,'_poi_likeli','.txt'),row.names = F,col.names = F)
writeMM(result.B.list[[2]],file=paste0(output.labels,'/post_',label,'_poi_gamma','.mtx'))
write.table((result.prob),file=paste0(output.labels,'/post_', label,'.txt'),row.names = F,append = F,col.names = F)
if(outlier.switch){
saveRDS(conditional.S.list,file=paste0(output.labels,'/post_', label,'_','outliers.RData'))
}
}
difference<-abs(mean(result.B.list[[1]][1:round(quantile(1:length(result.B.list[[1]]),probs = 0.25))])-stored.bf)
print(difference)
if(difference<epsilon){
break
}else{
stored.bf<-mean(result.B.list[[1]][1:round(quantile(1:length(result.B.list[[1]]),probs = 0.25))])
}
}
return(list(result.B.list,C.list,result.prob,conditional.S.list,prob.list))
}
######## Burning step###########
previous.result<-list()
all.C.list[[i]]<-Module.Cauchy.Shotgun(z.list[[i]],ld.list[[i]],epsilon=epsilon.list[[i]],
Max.Model.Dim=Max.Model.Dim,lambda = lambda.list[[i]],
outlier.switch=outlier.switch,tau=tau,
num.causal = num.causal,y.var=y.var,
label = label.list[[i]],output.labels = output.labels,
effect.size.prior=effect.size.prior,model.prior=model.prior,inner.all.iter = all.inner.iter)
print('all c list and dims')
print(length(all.C.list[[i]]))
print(class(all.C.list[[i]]))
print(all.C.list[[i]])
########Run fine-mapping step (module function) for each locus included in the analysis
#for(i in 1:L){
#  t0=Sys.time()
#  all.C.list[[i]]<-Module.Cauchy.Shotgun(z.list[[i]],ld.list[[i]],epsilon=epsilon.list[[i]],
#                                         Max.Model.Dim=Max.Model.Dim,lambda = lambda.list[[i]],
#                                         outlier.switch=outlier.switch,tau=tau,
#                                         num.causal = num.causal,y.var=y.var,
#                                         label = label.list[[i]],output.labels = output.labels,
#                                         effect.size.prior=effect.size.prior,model.prior=model.prior,inner.all.iter = all.inner.iter)
#  t1=Sys.time()-t0
#  print(paste0('This is locus ',i,' burning time'))
#    print((t1))
#  }
########Running CARMA########
for(g in 1:all.iter){
if(outlier.switch){
delete.list<-list()
for(i in 1:L){
delete.list[[i]]<-integer(0)
if(nrow(all.C.list[[i]][[4]])!=0){
temp.delete.list<-c(all.C.list[[i]][[4]]$Index)
delete.list[[i]]<-temp.delete.list
}
}
}else{
delete.list<-list()
for(i in 1:L){
delete.list[[i]]<-integer(0)
}
}
#########If the list of annotations is non-empty, then the PIPs and functional annotations at all loci are aggregated for the M-step of the EM algorithm
if(!is.null(w.list)){
w<-matrix(NA,nrow=0,ncol=ncol(w.list[[1]]))
colnames(w)<-colnames(w.list[[1]])
for(i in 1:L){
if(length(delete.list[[i]])!=0){
w<-rbind(w,w.list[[i]][-delete.list[[i]],])
}else{
w<-rbind(w,w.list[[i]])
}
}
}
for(i in 1:L){
previous.result[[i]]<-mean(all.C.list[[i]][[1]][[1]][1:round(quantile(1:length(all.C.list[[i]][[1]][[1]]),probs = 0.25))])
}
if(!is.null(w.list)){
if(EM.dist=='Poisson'){
if(!standardize.model.space){
model.space.count<-c()
for(i in 1:L){
if(length(delete.list[[i]])!=0){
model.space.count<-c(model.space.count,colSums(all.C.list[[i]][[1]][[2]][,-delete.list[[i]]]))
}else{
model.space.count<-c(model.space.count,colSums(all.C.list[[i]][[1]][[2]]))
}
}
}else{
model.space.count<-c()
for(i in 1:L){
if(length(delete.list[[i]])!=0){
indi.count<-colSums(all.C.list[[i]][[1]][[2]][,-delete.list[[i]]])
indi.count<-floor(colSums(all.C.list[[i]][[1]][[2]][,-delete.list[[i]]])/nrow(all.C.list[[i]][[1]][[2]][,-delete.list[[i]]])*Max.Model.Dim)
}else{
indi.count<-colSums(all.C.list[[i]][[1]][[2]])
indi.count<-floor(colSums(all.C.list[[i]][[1]][[2]])/nrow(all.C.list[[i]][[1]][[2]])*Max.Model.Dim)
}
model.space.count<-c(model.space.count,indi.count)
}
}
M.step.response=model.space.count
}
######The M step of the EM algorithm
if(EM.dist=='Logistic'){
M.step.response<-c()
for(i in 1:L){
if(length(delete.list[[i]])!=0){
indi.pip<-(all.C.list[[i]][[3]][-delete.list[[i]]])
}else{
indi.pip<-(all.C.list[[i]][[3]])
}
M.step.response<-c(M.step.response,indi.pip)
}
}
try.index<-try(glm.beta<-EM.M.step.func(input.response  = M.step.response ,w=w,input.alpha=input.alpha,EM.dist=EM.dist))
prior.prob.list<-list()
if(class(try.index)[1]!='try-error'){
for(i in 1:L){
if(prior.prob.computation=='Intercept.approx'){
glm.beta[1]=log((min(Max.Model.Dim,nrow(all.C.list[[i]][[1]][[2]])))*lambda.list[[i]]/(lambda.list[[i]]+p.list[[i]]))
prior.prob.list[[i]]<-(exp(w.list[[i]]%*%glm.beta)/(max(1+max(exp(w.list[[i]]%*%glm.beta)),min(Max.Model.Dim,nrow(all.C.list[[i]][[1]][[2]])))))
print(sort(prior.prob.list[[i]],decreasing = T)[1:10])
}
if(prior.prob.computation=='Logistic'){
prior.prob.list[[i]]<-plogis(w.list[[i]]%*%glm.beta)
print(sort(prior.prob.list[[i]],decreasing = T)[1:10])
}
if(!is.null(output.labels)){
write.table((glm.beta),file=paste0(output.labels,'/post_', label.list[[i]],'_theta.txt'),row.names = F,append = F,col.names = F)
}
}
model.prior='input.prob'
}else{
model.prior='Poisson'
prior.prob.list<-list()
for(i in 1:L){
prior.prob.list[[i]]<-list(NULL)
}
}
}else{
prior.prob.list<-list()
for(i in 1:L){
prior.prob.list[[i]]<-list(NULL)
}
}
#######Fine-mapping step for each locus, i.e., the E-step in the EM algorithm
for(i in 1:L){
t0=Sys.time()
all.C.list[[i]]<-Module.Cauchy.Shotgun(z=z.list[[i]],ld.list[[i]],input.conditional.S.list = all.C.list[[i]][[4]],
Max.Model.Dim=Max.Model.Dim,y.var=y.var,num.causal = num.causal,epsilon=epsilon.list[[i]],
C.list = all.C.list[[i]][[2]],prior.prob = prior.prob.list[[i]],
outlier.switch=outlier.switch,tau=tau,
lambda = lambda.list[[i]], label = label.list[[i]],output.labels = output.labels,
effect.size.prior=effect.size.prior,model.prior=model.prior,inner.all.iter = all.inner.iter)
t1=Sys.time()-t0
print(paste0('This is locus ',i,' computing time'))
print((t1))
}
difference<-0
for(i in 1:L){
difference<-difference+abs(previous.result[[i]]-mean(all.C.list[[i]][[1]][[1]][1:round(quantile(1:length(all.C.list[[i]][[1]][[1]]),probs = 0.25))]))
}
print(paste0('This is difference; ',difference))
if(difference<all.epsilon.threshold){
break
}
}
### Output of the results of CARMA
results.list<-list()
for(i in 1:L){
results.list[[i]]<-list()
pip=all.C.list[[i]][[3]]
credible.set<-credible.set.fun.improved(pip,ld.list[[i]],rho=rho.index)
credible.model<-credible.model.fun(all.C.list[[i]][[1]][[1]],all.C.list[[i]][[1]][[2]],bayes.threshold = BF.index)
results.list[[i]][[1]]<-pip
results.list[[i]][[2]]<-credible.set
results.list[[i]][[3]]<-credible.model
results.list[[i]][[4]]<-all.C.list[[i]][[4]]
names(results.list[[i]])<-c('PIPs','Credible set','Credible model','Outliers')
}
sink()
return(results.list)
}
library(CARMA)
library(data.table)
library(magrittr)
library(dplyr)
library(devtools)
library(R.utils)
library(Matrix)
library(MASS)
library(Rcpp)
library(RcppArmadillo)
library(RcppGSL)
library(glmnet)
#sumstat <- fread('/Users/hn9/Documents/GitHub/carmapy/tests/APOE_locus_sumstats.txt.gz',
#                 sep = "\t", header = T, check.names = F, data.table = F,
#                 stringsAsFactors = F)
#ld <- fread('/Users/hn9/Documents/GitHub/carmapy/tests/APOE_locus_ld.txt.gz',
#            sep = "\t", header = T, check.names = F, data.table = F,
#            stringsAsFactors = F)
sumstat<- fread(file = "/Users/hn9/Documents/GitHub/CARMA/Simulation Study/Sample_data/sumstats_chr1_200937832_201937832.txt.gz",
sep = "\t", header = T, check.names = F, data.table = F,
stringsAsFactors = F)
###### load the pair-wise LD matrix (assuming the same order of variants
###### as the variants in sumstat file)
ld =  fread(file = "/Users/hn9/Documents/GitHub/CARMA/Simulation Study/Sample_data/sumstats_chr1_200937832_201937832_ld.txt.gz",
sep = "\t", header = F, check.names = F, data.table = F,
stringsAsFactors = F)
z.list<-list()
ld.list<-list()
lambda.list<-list()
z.list[[1]]<-sumstat$Z
ld.list[[1]]<-as.matrix(ld)
lambda.list[[1]]<-1
CARMA.results<-test_CARMA_fixed_sigma(z.list,ld.list,lambda.list=lambda.list,
outlier.switch=T)
getwd()
library(CARMA)
library(data.table)
library(magrittr)
library(dplyr)
library(devtools)
library(R.utils)
library(Matrix)
library(MASS)
library(Rcpp)
library(RcppArmadillo)
library(RcppGSL)
library(glmnet)
library(coloc)
data(coloc_test_data)
attach(coloc_test_data)
z.list<-list()
ld.list<-list()
lambda.list<-list()
z.list[[1]]<-D3$beta/sqrt(D3$varbeta)
ld.list[[1]]<-D3$LD
lambda.list[[1]]<-1
CARMA.results<-CARMA(z.list,ld.list,lambda.list=lambda.list,
outlier.switch=T)
CARMA.results=CARMA.results[[1]]
names(coloc_test_data)
setwd("/Users/hn9/Documents/GitHub/slalom-susie/FM-benchmarking")
library(CARMA)
library(data.table)
library(dplyr)
library(susieR)
library(coloc)
data(coloc_test_data)
attach(coloc_test_data)
# Benchmarking tests:
# 1. No changes to D3
# 2. Changing sign of lead SNP z-score
# 3. Changing sign of second most significant SNP z-score
# 4. Duplicate lead SNP to create perfect linkage
# 5. Slightly change z-score of duplicated lead SNP (-2)
#######################################################################################################
# 1. No changes to D3
#######################################################################################################
# CARMA D3 Fine-mapping
d3_df <- as.data.frame(coloc_test_data$D3)
sumstats_d3 <- select(d3_df, snp, position, beta, varbeta, N, sdY,type,MAF)
rownames(sumstats_d3) <- as.character(1:nrow(sumstats_d3))
sumstats_d3$Z <- D3$beta/sqrt(D3$varbeta)
ld_d3 <- subset(d3_df, select = -c(snp, position, beta, varbeta, N, sdY,type,MAF))
z.list<-list()
ld.list<-list()
lambda.list<-list()
z.list[[1]]<-sumstats_d3$Z
ld.list[[1]]<-as.matrix(ld_d3)
lambda.list[[1]]<-1
start_time <- Sys.time()
time_taken <- system.time({
CARMA.results <- CARMA(z.list, ld.list, lambda.list = lambda.list, outlier.switch = T)
})
end_time <- Sys.time()
print(paste("CPU Time taken: ", time_taken['elapsed'], " seconds"))
print(paste("Wall-clock Time taken: ", difftime(end_time, start_time, units = "secs"), " seconds"))
start_time <- Sys.time()
time_taken <- system.time({
CARMA.results <- CARMA(z.list, ld.list, lambda.list = lambda.list, outlier.switch = F)
})
end_time <- Sys.time()
print(paste("CPU Time taken: ", time_taken['elapsed'], " seconds"))
print(paste("Wall-clock Time taken: ", difftime(end_time, start_time, units = "secs"), " seconds"))
z_vector <- unlist(sumstats_d3$Z)
ld_matrix <- as.matrix(ld_d3)
SSr=susie_rss(z = z_vector,R=ld_matrix,n=1000)
start_time <- Sys.time()
time_taken <- system.time({
SSr=susie_rss(z = z_vector,R=ld_matrix,n=1000)
})
end_time <- Sys.time()
print(paste("CPU Time taken: ", time_taken['elapsed'], " seconds"))
print(paste("Wall-clock Time taken: ", difftime(end_time, start_time, units = "secs"), " seconds"))
library(CARMA)
library(data.table)
library(dplyr)
sumstat <- fread('/Users/hn9/Documents/GitHub/fine-mapping-inf/susieinf/loci/APOE_LDL_locus_sumstat_with_dentist.txt.gz')
